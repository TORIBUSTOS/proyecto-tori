# Control Profesional de Importaci√≥n por Batches

## üìã Resumen de Implementaci√≥n

Sistema completo de control de importaci√≥n implementado para evitar duplicados y gestionar hist√≥ricos de forma profesional.

---

## ‚úÖ Objetivos Cumplidos

1. ‚úÖ **Control de Batches**: Cada Excel subido crea un batch con ID √∫nico
2. ‚úÖ **Detecci√≥n de Duplicados**: Hash SHA256 con restricci√≥n √∫nica en BD
3. ‚úÖ **Dashboard Inteligente**: Muestra solo el √∫ltimo batch por defecto
4. ‚úÖ **Trazabilidad**: Cada movimiento sabe de qu√© importaci√≥n proviene
5. ‚úÖ **HTTP 409**: Respuesta est√°ndar para archivos duplicados

---

## üóÇÔ∏è Estructura de Archivos

### Nuevos Archivos Creados

```
backend/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ import_batch.py                    ‚úÖ Modelo de batches
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ file_hash.py                       ‚úÖ C√°lculo de hash SHA256
‚îî‚îÄ‚îÄ database/
    ‚îî‚îÄ‚îÄ migrate_add_batches.py             ‚úÖ Script de migraci√≥n
```

### Archivos Modificados

```
backend/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                        ‚úÖ Registro de ImportBatch
‚îÇ   ‚îî‚îÄ‚îÄ movimiento.py                      ‚úÖ Agregado batch_id + relationship
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îî‚îÄ‚îÄ consolidar.py                      ‚úÖ L√≥gica de batches y duplicados
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ routes.py                          ‚úÖ Endpoints actualizados
‚îî‚îÄ‚îÄ database/
    ‚îî‚îÄ‚îÄ init_db.py                         ‚úÖ Importa ImportBatch
```

---

## üîß Cambios T√©cnicos Detallados

### 1. Modelo ImportBatch

**Archivo**: `backend/models/import_batch.py`

```python
from sqlalchemy import Column, Integer, String, DateTime, func, UniqueConstraint
from backend.database.connection import Base

class ImportBatch(Base):
    __tablename__ = "import_batches"

    id = Column(Integer, primary_key=True, index=True)
    filename = Column(String, nullable=False)
    file_hash = Column(String, nullable=False, index=True)
    imported_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    rows_inserted = Column(Integer, default=0, nullable=False)

    __table_args__ = (
        UniqueConstraint("file_hash", name="uq_import_batches_file_hash"),
    )
```

**Caracter√≠sticas**:
- Hash √∫nico previene duplicados a nivel de BD
- Timestamp autom√°tico del servidor
- Contador de filas insertadas

---

### 2. Modelo Movimiento Actualizado

**Archivo**: `backend/models/movimiento.py`

**Cambios**:
```python
from sqlalchemy.orm import relationship

batch_id = Column(Integer, ForeignKey("import_batches.id"), nullable=True, index=True)
batch = relationship("ImportBatch")
```

**Beneficios**:
- Relaci√≥n expl√≠cita con ImportBatch
- √çndice en batch_id para consultas r√°pidas
- Nullable para movimientos antiguos

---

### 3. Funci√≥n consolidar_excel

**Archivo**: `backend/core/consolidar.py`

**Flujo Actualizado**:

```
1. Calcular hash SHA256 del archivo
2. Verificar si existe en BD
   ‚îú‚îÄ Si existe ‚Üí ValueError("DUPLICATE_FILE: ...")
   ‚îî‚îÄ Si no existe ‚Üí Continuar
3. Crear ImportBatch
4. db.flush() para obtener batch.id
5. Insertar movimientos con batch_id
6. Actualizar batch.rows_inserted
7. db.commit() una sola vez
8. Retornar batch_id
```

**C√≥digo clave**:
```python
# Detecci√≥n de duplicados
file_hash = calculate_file_hash(file_bytes)
existing_batch = db.query(ImportBatch).filter(ImportBatch.file_hash == file_hash).first()
if existing_batch:
    raise ValueError(
        f"DUPLICATE_FILE: Este archivo ya fue importado el {existing_batch.imported_at.isoformat()} "
        f"con {existing_batch.rows_inserted} movimientos (batch_id: {existing_batch.id})"
    )

# Creaci√≥n de batch
batch = ImportBatch(filename=filename, file_hash=file_hash, rows_inserted=0)
db.add(batch)
db.flush()

# Asociar movimientos
movimiento = Movimiento(..., batch_id=batch.id)
```

---

### 4. Endpoints API

#### A) POST /api/consolidar

**Cambios**:
```python
# Respuesta exitosa
{
    "status": "success",
    "batch_id": 123,
    "insertados": 50,
    ...
}

# Respuesta duplicado (HTTP 409)
{
    "detail": "Este archivo ya fue importado el 2025-12-14T10:30:00..."
}
```

**Manejo de errores**:
```python
except ValueError as e:
    error_msg = str(e)
    if error_msg.startswith("DUPLICATE_FILE:"):
        raise HTTPException(status_code=409, detail=error_msg.replace("DUPLICATE_FILE: ", ""))
    raise HTTPException(status_code=400, detail=error_msg)
```

---

#### B) POST /api/proceso-completo

**Cambios**:
```python
{
    "status": "success",
    "batch_id": 123,
    "consolidar": {
        "batch_id": 123,
        "insertados": 50,
        ...
    },
    ...
}
```

---

#### C) GET /api/dashboard

**Par√°metros nuevos**:
- `batch_id` (opcional): Ver batch espec√≠fico
- `mostrar_historico` (opcional): Ver todos los movimientos

**L√≥gica**:
```python
# Por defecto: √∫ltimo batch
if not batch_id and not mostrar_historico:
    ultimo_batch = db.query(ImportBatch).order_by(ImportBatch.imported_at.desc()).first()
    batch_filter = ultimo_batch.id

# Filtrar movimientos
query_base = db.query(Movimiento).filter(Movimiento.batch_id == batch_filter)
```

**Respuesta**:
```json
{
    "resumen_cuenta": {
        "saldo_total": 150000.50,
        "movimientos_mes": 23,
        "categorias_activas": 8
    },
    "ultimos_movimientos": [...],
    "mensaje": "Mostrando √∫ltimo batch #5 (extracto_diciembre.xlsx) - 50 movimientos",
    "batch_id": 5,
    "mostrar_historico": false
}
```

---

### 5. Migraci√≥n de Base de Datos

**Archivo**: `backend/database/migrate_add_batches.py`

**Ejecutar**:
```bash
python -m backend.database.migrate_add_batches
```

**Acciones**:
1. Crea tabla `import_batches`
2. Crea √≠ndice √∫nico en `file_hash`
3. Agrega columna `batch_id` a `movimientos`
4. Crea √≠ndice en `batch_id`

**Estado**: ‚úÖ Ejecutado exitosamente

---

## üöÄ Uso del Sistema

### Caso 1: Primera importaci√≥n

```bash
POST /api/proceso-completo
Content-Type: multipart/form-data
archivo: extracto_enero.xlsx

# Respuesta HTTP 200
{
    "status": "success",
    "batch_id": 1,
    "consolidar": {
        "insertados": 45,
        "batch_id": 1
    }
}
```

---

### Caso 2: Archivo duplicado

```bash
POST /api/proceso-completo
archivo: extracto_enero.xlsx (mismo archivo)

# Respuesta HTTP 409
{
    "detail": "Este archivo ya fue importado el 2025-12-14T15:30:00 con 45 movimientos (batch_id: 1)"
}
```

---

### Caso 3: Ver dashboard (√∫ltimo batch)

```bash
GET /api/dashboard

# Respuesta
{
    "mensaje": "Mostrando √∫ltimo batch #3 (extracto_diciembre.xlsx) - 50 movimientos",
    "batch_id": 3,
    "resumen_cuenta": { ... }
}
```

---

### Caso 4: Ver batch espec√≠fico

```bash
GET /api/dashboard?batch_id=1

# Respuesta
{
    "mensaje": "Mostrando batch #1 (extracto_enero.xlsx) - 45 movimientos",
    "batch_id": 1,
    ...
}
```

---

### Caso 5: Ver hist√≥rico completo

```bash
GET /api/dashboard?mostrar_historico=true

# Respuesta
{
    "mensaje": "Mostrando hist√≥rico completo - 150 movimientos",
    "batch_id": null,
    "mostrar_historico": true,
    ...
}
```

---

## üìä Base de Datos

### Tabla import_batches

| Campo | Tipo | Descripci√≥n |
|-------|------|-------------|
| id | INTEGER | PK, autoincremental |
| filename | VARCHAR | Nombre del archivo |
| file_hash | VARCHAR | SHA256 (√∫nico) |
| imported_at | DATETIME | Timestamp autom√°tico |
| rows_inserted | INTEGER | Cantidad de movimientos |

**√çndices**:
- PRIMARY KEY en `id`
- UNIQUE INDEX en `file_hash`

---

### Tabla movimientos (actualizada)

| Campo | Tipo | Descripci√≥n |
|-------|------|-------------|
| ... | ... | (campos existentes) |
| batch_id | INTEGER | FK a import_batches |

**√çndices**:
- INDEX en `batch_id`

---

## üéØ Beneficios

### 1. No m√°s duplicados
- Imposible importar el mismo archivo dos veces
- Detecci√≥n instant√°nea por hash
- Mensaje claro con fecha de importaci√≥n previa

### 2. Saldos correctos
- Dashboard no mezcla hist√≥ricos
- Cada batch es independiente
- Vista clara de cada per√≠odo

### 3. Trazabilidad completa
- Cada movimiento sabe de qu√© archivo viene
- Auditor√≠a de importaciones
- Posibilidad de revertir por batch

### 4. Flexibilidad
- Ver √∫ltimo batch (por defecto)
- Ver batch espec√≠fico
- Ver hist√≥rico completo
- Performance optimizado con √≠ndices

---

## üîç Testing Recomendado

### Test 1: Importaci√≥n normal
```bash
# Subir extracto nuevo
POST /api/proceso-completo con extracto_test1.xlsx
# Esperado: HTTP 200, batch_id=1
```

### Test 2: Duplicado
```bash
# Subir mismo archivo
POST /api/proceso-completo con extracto_test1.xlsx
# Esperado: HTTP 409, mensaje de duplicado
```

### Test 3: Dashboard √∫ltimo batch
```bash
GET /api/dashboard
# Esperado: Muestra solo movimientos del √∫ltimo batch
```

### Test 4: Dashboard hist√≥rico
```bash
# Subir extracto_test2.xlsx
POST /api/proceso-completo con extracto_test2.xlsx
# Ver hist√≥rico
GET /api/dashboard?mostrar_historico=true
# Esperado: Suma de ambos batches
```

### Test 5: Dashboard batch espec√≠fico
```bash
GET /api/dashboard?batch_id=1
# Esperado: Solo movimientos del batch 1
```

---

## üìù Notas de Desarrollo

### En desarrollo
Si necesitas resetear la BD:
```bash
# Borrar BD (solo desarrollo)
rm toro.db

# Recrear tablas
python -m backend.database.init_db

# Aplicar migraci√≥n
python -m backend.database.migrate_add_batches
```

### En producci√≥n
- La migraci√≥n es no-destructiva
- Los movimientos antiguos tendr√°n `batch_id=NULL`
- Las nuevas importaciones tendr√°n batch_id v√°lido

---

## ‚úÖ Checklist de Implementaci√≥n

- [x] Modelo ImportBatch creado
- [x] Modelo Movimiento actualizado con batch_id
- [x] Relaci√≥n ORM configurada
- [x] Funci√≥n calculate_file_hash implementada
- [x] consolidar_excel actualizado con detecci√≥n de duplicados
- [x] Endpoint /api/consolidar con HTTP 409
- [x] Endpoint /api/proceso-completo con batch_id
- [x] Endpoint /api/dashboard con filtrado por batch
- [x] Migraci√≥n de BD ejecutada
- [x] √çndices creados para performance
- [x] Restricci√≥n √∫nica en file_hash

---

## üéâ Resultado Final

El sistema ahora tiene:

1. ‚úÖ **Control profesional de importaci√≥n**
2. ‚úÖ **Prevenci√≥n de duplicados autom√°tica**
3. ‚úÖ **Dashboard que muestra datos correctos**
4. ‚úÖ **Trazabilidad completa**
5. ‚úÖ **API REST con c√≥digos HTTP correctos**
6. ‚úÖ **Base de datos optimizada**

**Estado**: üü¢ PRODUCCI√ìN READY
